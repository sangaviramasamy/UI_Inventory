const path = require('path')
const fs = require('fs')
const archiver = require('archiver')
const chalk = require('chalk')
const pathUtil = require('../utils/path')
const { getOutputPath, getComponentsMap, getBaseDirName, getPackageDirName } = require('./utils')
const { addPublishPackage, writePublishPackages, resetComponentsMap } = require('./publish-list-generator')

const projectDir = pathUtil.root.path

const packageJson = require(path.join(projectDir,'package.json'))

const packagePrefix = '@blibli/blue.'

function _archive (output, archiveAction, closeHandler) {
  const archive = archiver('tar', { gzipOptions: { level: 9 }, gzip: true })
  // Listen for all archive data to be written
  output.on('close', () => closeHandler(archive))
  // Good practice to catch this error explicitly
  archive.on('error', err => { console.log(`[ERROR] ${err}`) })
  // Pipe archive data to the file
  archive.pipe(output)
  archiveAction(archive)
  archive.finalize()
}

function _createPackageJson (dirName, file, srcPackageJson) {
  const outputFile = getOutputPath({ file })
  const fileName = path.basename(outputFile)
  const outputJsonDir = path.join('dist', 'metadata', dirName)
  const outputJsonFile = path.join(outputJsonDir, 'package.json')

  const output = {
    ...packageJson,
    main: outputFile,
    scripts: {},
    devDependencies: {},
    files: [
      'lib',
      'dist',
      'src',
      'README.md'
    ],
    name: packagePrefix + dirName,
    ...srcPackageJson
  }

  console.log(chalk.blue('writing json file'))
  if (!fs.existsSync(outputJsonDir)) {
    fs.mkdirSync(outputJsonDir, { recursive: true })
  }
  // write file
  fs.writeFileSync(outputJsonFile, JSON.stringify(output, null, '  '))
  return outputJsonFile
}

let processComponentCount = 0
// array for publish packages
const publishPackages = []

function packComponents() {
  const components = getComponentsMap() 

  components.forEach(param => {
    const { file, publish } = param
    
    const outputFile = getOutputPath(param)
    const outputDir = path.dirname(outputFile)
    const outputFileName = path.basename(outputFile)
    const dir = path.dirname(file)
    const name = path.basename(file)
    const dirName = getBaseDirName(file)
    const packageName =  getPackageDirName(file)
    const srcPackageJson = JSON.parse(fs.readFileSync(path.join(dir, 'package.json'), 'utf-8'))
    const distDir = 'dist'
    const srcDir = 'src'
    const outputResourceDir = path.join(distDir, 'packages')
    const outputTarFileDir = path.join(outputResourceDir, packageName)
    const outputResourcePath = path.join(outputResourceDir, dirName + '.tgz')
    if (!fs.existsSync(outputResourceDir)) {
      fs.mkdirSync(outputResourceDir)
    }
  
    if (!fs.existsSync(outputTarFileDir)) {
      fs.mkdirSync(outputTarFileDir, { recursive: true })
    }
  
    // write file
    const packageJsonFile = _createPackageJson(
      packageName,
      path.join(packageName, outputFileName),
      srcPackageJson
    )
    const outputResource = fs.createWriteStream(outputResourcePath)
    _archive(outputResource,
      archive => {
        archive.directory(dir, path.join('package', srcDir, packageName))
        archive.directory(outputDir, path.join('package', distDir, packageName))
        archive.file(packageJsonFile, {
          name: 'package.json',
          prefix: 'package',
        })
        archive.file(path.join(dir, 'README.md'), {
          name: 'README.md',
          prefix: 'package',
        })
      }, () => {
        console.log(chalk.green('Done compressing'))
        processComponentCount++
        if (publish) {
          addPublishPackage(publishPackages, outputResourcePath)
        }
  
        if (processComponentCount === components.length) {
          writePublishPackages(fs, path, publishPackages)
          resetComponentsMap(fs, components)
        }
      })
  })
}

module.exports = {
  packComponents
}